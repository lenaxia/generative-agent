llm_providers:
  #openai:
  #  name: localai
  #  type: openai
  #  llm_class: DEFAULT
  #  config:
  #    model_name: qwen2.5-72b-instruct-iq4_xs
  #    base_url: http://192.168.5.74:8080/v1
  bedrock-strong:
    name: bedrock-sonnet
    type: bedrock
    llm_class: default
    config:
      model: anthropic.claude-3-sonnet-20240229-v1:0
      temperature: 0.5
  bedrock-weak:
    name: bedrock-haiku
    type: bedrock
    llm_class: weak
    config:
      model: anthropic.claude-3-haiku-20240307-v1:0
      temperature: 0.5
    
logging:
  log_file: logs/supervisor.log
  log_level: info
  log_file_max_size: 1024
  disable_console_logging: true

agents:
  slack_agent:
    agent_class: SlackAgent
    config:
      slack_channel: general
      status_channel: logging
      monitored_event_types:
        - message
      online_message: "SlackAgent is online and ready to receive messages."
      llm_class: default
      history_limit: 5
  planning_agent:
    agent_class: PlanningAgent
    config:
      llm_class: default
  weather_agent:
    agent_class: WeatherAgent
    config:
      llm_class: weak