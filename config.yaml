# Universal Agent System Configuration
# This configuration supports both legacy agents and the new Universal Agent system

# Framework Configuration
framework:
  type: "strands"  # Options: "strands", "langchain" (legacy)
  enable_universal_agent: true
  enable_legacy_agents: false  # For backward compatibility during migration

# LLM Provider Configuration
llm_providers:
  # Bedrock Configuration
  bedrock:
    # Model mapping for semantic types
    models:
      WEAK: "anthropic.claude-3-haiku-20240307-v1:0"
      DEFAULT: "us.amazon.nova-pro-v1:0"
      STRONG: "us.anthropic.claude-3-5-sonnet-20241022-v2:0"
    
    # Default parameters
    parameters:
      temperature: 0.3
      max_tokens: 4096
      region: "us-west-2"
    
    # Legacy provider configs (for compatibility)
    bedrock-weak:
      name: bedrock-haiku
      type: bedrock
      llm_class: weak
      config:
        model: anthropic.claude-3-haiku-20240307-v1:0
        temperature: 0.5
    
    bedrock-strong:
      name: bedrock-sonnet
      type: bedrock
      llm_class: default
      config:
        model: anthropic.claude-3-sonnet-20240229-v1:0
        temperature: 0.5

  # OpenAI Configuration (optional)
  openai:
    models:
      WEAK: "gpt-3.5-turbo"
      DEFAULT: "gpt-4"
      STRONG: "gpt-4-turbo"
    
    parameters:
      temperature: 0.3
      max_tokens: 4096

# Universal Agent Configuration
universal_agent:
  # Role to LLM type mapping
  role_llm_mapping:
    planning: "STRONG"      # Complex reasoning
    analysis: "STRONG"      # Complex analysis
    coding: "STRONG"        # Code generation
    search: "WEAK"          # Simple search
    weather: "WEAK"         # Simple lookup
    summarizer: "DEFAULT"   # Text processing
    slack: "DEFAULT"        # Conversational
    default: "DEFAULT"      # Fallback
  
  # Performance settings
  performance:
    max_concurrent_agents: 5
    agent_timeout: 300      # 5 minutes
    enable_caching: true
    cache_ttl: 3600        # 1 hour

# Task Management Configuration
task_management:
  max_concurrent_tasks: 5
  task_timeout: 300
  enable_pause_resume: true
  checkpoint_interval: 60
  max_retries: 3
  retry_delay: 1.0

# Request Manager Configuration
request_manager:
  max_active_requests: 20
  request_timeout: 1800    # 30 minutes
  cleanup_interval: 300    # 5 minutes

# Message Bus Configuration
message_bus:
  max_subscribers: 100
  queue_size: 1000
  enable_persistence: false

# Logging Configuration
logging:
  level: "INFO"
  log_file: "logs/supervisor.log"
  log_file_max_size: 1024
  disable_console_logging: false
  
  # Structured logging
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  
  # Component-specific log levels
  loggers:
    llm_provider: "DEBUG"
    supervisor: "INFO"
    universal_agent: "INFO"

# MCP Integration
mcp:
  enabled: true
  config_file: "config/mcp_config.yaml"
  
# Legacy Agent Configuration (for backward compatibility)
agents:
  slack_agent:
    agent_class: SlackAgent
    config:
      slack_channel: general
      status_channel: logging
      monitored_event_types:
        - message
      online_message: "SlackAgent is online and ready to receive messages."
      llm_class: default
      history_limit: 5
      
  planning_agent:
    agent_class: PlanningAgent
    config:
      llm_class: default
      
  weather_agent:
    agent_class: WeatherAgent
    config:
      llm_class: weak
      
  summary_agent:
    agent_class: TextSummarizerAgent
    config:
      llm_class: default
      skip_if_text_shorter_than: 600
      target_summary_length: 300

# Feature Flags
feature_flags:
  enable_universal_agent: true
  enable_mcp_integration: true
  enable_task_scheduling: true
  enable_pause_resume: true
  enable_legacy_agents: false

# Development Settings
development:
  debug_mode: false
  mock_llm_responses: false
  enable_profiling: false