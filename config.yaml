# Universal Agent System Configuration
# Clean configuration for StrandsAgent-based Universal Agent system

# Framework Configuration
framework:
  type: "strands"

# LLM Provider Configuration
llm_providers:
  # Bedrock Configuration
  bedrock:
    # Model mapping for semantic types
    models:
      WEAK: "anthropic.claude-3-haiku-20240307-v1:0"
      DEFAULT: "us.amazon.nova-pro-v1:0"
      STRONG: "us.anthropic.claude-3-5-sonnet-20241022-v2:0"
    
    # Default parameters
    parameters:
      temperature: 0.3
      max_tokens: 4096
      region: "us-west-2"

  # OpenAI Configuration (optional)
  openai:
    models:
      WEAK: "gpt-3.5-turbo"
      DEFAULT: "gpt-4"
      STRONG: "gpt-4-turbo"
    
    parameters:
      temperature: 0.3
      max_tokens: 4096

# Universal Agent Configuration
universal_agent:
  # Role to LLM type mapping
  role_llm_mapping:
    planning: "STRONG"      # Complex reasoning
    analysis: "STRONG"      # Complex analysis
    coding: "STRONG"        # Code generation
    search: "WEAK"          # Simple search
    weather: "WEAK"         # Simple lookup
    summarizer: "DEFAULT"   # Text processing
    slack: "DEFAULT"        # Conversational
    default: "DEFAULT"      # Fallback
  
  # Performance settings
  performance:
    max_concurrent_agents: 5
    agent_timeout: 300      # 5 minutes
    enable_caching: true
    cache_ttl: 3600        # 1 hour

# Task Management Configuration
task_management:
  max_concurrent_tasks: 5
  task_timeout: 300
  enable_pause_resume: true
  checkpoint_interval: 60
  max_retries: 3
  retry_delay: 1.0

# Request Manager Configuration
request_manager:
  max_active_requests: 20
  request_timeout: 1800    # 30 minutes
  cleanup_interval: 300    # 5 minutes

# Message Bus Configuration
message_bus:
  max_subscribers: 100
  queue_size: 1000
  enable_persistence: false

# Logging Configuration
logging:
  level: "INFO"
  log_file: "logs/supervisor.log"
  log_file_max_size: 1024
  disable_console_logging: false
  
  # Structured logging
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  
  # Component-specific log levels
  loggers:
    llm_provider: "DEBUG"
    supervisor: "INFO"
    universal_agent: "INFO"

# MCP Integration
mcp:
  enabled: true
  config_file: "config/mcp_config.yaml"

# Feature Flags
feature_flags:
  enable_universal_agent: true
  enable_mcp_integration: true
  enable_task_scheduling: true
  enable_pause_resume: true

# Development Settings
development:
  debug_mode: false
  mock_llm_responses: false
  enable_profiling: false