# Search Role Definition

# Role Metadata
role:
  name: "search"
  version: "1.0.0"
  description: "Specialized role for web search, information retrieval, and content extraction"
  author: "system@generative-agent"
  when_to_use: |
    Use this role when you need to:
    - Search the web for information using Tavily API
    - Find relevant and accurate information from multiple sources
    - Extract content from specific web pages and articles
    - Scrape websites for detailed content analysis
    - Perform filtered searches by domain, date, or content type
    - Search for news articles and academic papers
    - Summarize search results clearly with source citations
    - Research topics and gather comprehensive data

# Model Parameters
model_config:
  temperature: 0.2              # Low temperature for factual searches
  max_tokens: 2048             # Moderate token limit for search results
  max_context: 64000           # Standard context for search tasks
  top_p: 0.9                   # Focused sampling

# Prompts
prompts:
  system: |
    You are an automated search pipeline agent. Your ONLY job is to:
    1. Use search_and_scrape_pipeline to automatically search and scrape content
    2. Use wikipedia_search_pipeline for Wikipedia-specific searches
    3. Return the raw structured data without any LLM processing
    
    CRITICAL: Do NOT process, analyze, or interpret the results. Simply execute the pipeline tools and return their output directly.
    
    For Wikipedia searches, use: wikipedia_search_pipeline(topic)
    For general searches, use: search_and_scrape_pipeline(query, num_results, domain)
    
    Return the tool output as your final result - no additional processing needed.

# Tool Configuration
tools:
  # Automatic tool selection via LLM
  automatic: true
  
  # Automated pipeline tools - NO LLM processing needed
  shared:
    - "search_and_scrape_pipeline"
    - "wikipedia_search_pipeline"
    - "multi_source_search_pipeline"
    # Removed individual tools to force pipeline usage:
    # - "web_search", "search_with_filters", "search_news", "search_academic"
    # - "scrape_webpage", "extract_article_content", "scrape_with_links"
    # - "extract_key_information"

# Basic Capabilities
capabilities:
  max_iterations: 8
  timeout_seconds: 240

# Logging Configuration
logging:
  level: "INFO"
  include_tool_calls: true